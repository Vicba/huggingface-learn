{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Unit1 - Fundamentals\n"
      ],
      "metadata": {
        "id": "73QsPFa-cpeY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Data types\n",
        "\n",
        "\n",
        "| Feature                 | Image                                            | Video                                           | Audio                                              | Tabular Data                                                   |\n",
        "|-------------------------|--------------------------------------------------|-------------------------------------------------|---------------------------------------------------|----------------------------------------------------------------|\n",
        "| **Type**                | Single moment in time                            | Sequence of images over time                    | Single moment in time                             | Structured data organized in rows and columns                   |\n",
        "| **Data Representation** | Typically a 2D array of pixels                   | Typically a 3D array of frames                  | Typically a 1D array of audio samples             | Typically a 2D array of features as columns and rows (spreadsheet, database tables) |\n",
        "| **File Types**          | JPEG, PNG, RAW, etc.                             | MP4, AVI, MOV, etc.                             | WAV, MP3, FLAC, etc.                              | CSV, Excel (.xlsx, .xls), Database formats, etc.               |\n",
        "| **Data Augmentation**   | Flipping, rotating, cropping                     | Temporal jittering, speed variations, occlusion | Background noise addition, reverberation, spectral manipulation | ROSE, SMOTE, ADASYN                                             |\n",
        "| **Feature Extraction**  | Edges, textures, colors                          | Edges, textures, colors, optical flow, trajectories | Spectrogram, Mel-Frequency Cepstral Coefficients (MFCCs), Chroma features | Statistical analysis, Feature engineering, Data aggregation     |\n",
        "| **Learning Models**     | CNNs                                             | RNNs, 3D CNNs                                   | CNNs, RNNs                                         | Linear Regression, Decision Trees, Random Forests, Gradient Boosting |\n",
        "| **Machine Learning Tasks** | Image classification, Segmentation, Object Detection | Video action recognition, temporal modeling, tracking | Speech recognition, speaker identification, music genre classification | Regression, Classification, Clustering                           |\n",
        "| **Computational Cost**  | Less expensive                                  | More expensive                                  | Moderate to high                                  | Generally less expensive compared to others                     |\n",
        "| **Applications**        | Facial recognition for security access control  | Sign language interpretation for live communication | Voice assistants, Speech-to-text, Music genre classification | Predictive modeling, Fraud detection, Weather forecasting       |"
      ],
      "metadata": {
        "id": "j9kztSGpcu_i"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Understanding Resolution in Digital Imaging\n",
        "\n",
        "Spatial resolution refers to the smallest distinguishable detail in an image and is often measured in line pairs per unit distance or pixels per unit distance. The meaningfulness of spatial resolution is context-dependent, varying according to the spatial units used. For example, a 20-megapixel camera typically offers higher detail resolution than an 8-megapixel camera. Intensity resolution relates to the smallest detectable change in intensity level and is often limited by the hardware’s capabilities. It’s quantized in binary increments, such as 8 bits or 256 levels. The perception of these intensity changes is influenced by various factors, including noise, saturation, and the capabilities of human vision.\n",
        "\n",
        "![](https://huggingface.co/datasets/hf-vision/course-assets/resolve/4def8c412ee6b08f4522e818a0474d155363d87b/pic_7.png)"
      ],
      "metadata": {
        "id": "5OS_Ok01kC6n"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Imaging in real-life\n",
        "\n",
        "As human species, we only see a fraction of the spectrum. We call that the visible spectrum. The image below shows us just how narrow it is:\n",
        "\n",
        "![](https://huggingface.co/datasets/hf-vision/course-assets/resolve/main/human_spectrum.jpg)\n",
        "\n",
        "To see more than what Mother Nature has given us, we need sensors capturing beyond that spectrum. In other words, we need to detect things at different wavelengths. Infrared (IR) is used in night vision devices and some astronomical observations. Magnetic resonance uses strong magnetic fields and radio waves to image soft human tissues. We created ways to see things that do not rely on light. For instance, electron microscopy uses electrons to zoom in at much higher resolution than traditional light. Ultrasound is another great example. Ultrasound imaging harnesses sound waves to create detailed, real-time images of internal organs and tissues, offering a non-invasive and dynamic perspective that goes beyond what is achievable with standard light-based imaging methods."
      ],
      "metadata": {
        "id": "yBk6yXpqkv0B"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## What is computer vision\n",
        "\n",
        "Computer vision is the science and technology of making machines see. It involves the development of theoretical and algorithmic methods to acquire, process, analyze, and understand visual data, and to use this information to produce meaningful representations, descriptions, and interpretations of the world\n",
        "\n",
        "![](https://huggingface.co/datasets/hf-vision/course-assets/resolve/743a2a115b53f258c9e6bc7744534d9e03b8a124/CV_in_defintiion.png)\n",
        "\n",
        "### CV Tasks\n",
        "\n",
        "We have seen before that computer vision is really hard for computers because they have no previous knowledge of the world. In our example, we start knowing what a ball is, how to track its movement, how objects usually move in space, how to estimate when the ball will reach us, where your foot is, how a foot moves, and how to estimate how much force you need to hit the ball. If we were to break this down into specific computer vision tasks, we would have:\n",
        "\n",
        "Scene Recognition\n",
        "\n",
        "- Object Recognition\n",
        "- Object Detection\n",
        "- Segmentation (instance, semantic)\n",
        "- Tracking\n",
        "- Dynamic Environment Adaptation\n",
        "- Path Planning\n",
        "\n",
        "You will read more about the core tasks of computer vision in the Computer Vision Tasks chapter. But there are many more tasks that computer vision can do! Here is a non-exhaustive list:\n",
        "\n",
        "- Image Captioning\n",
        "- Image Classification\n",
        "- Image Description\n",
        "- Anomaly Detection\n",
        "- Image Generation\n",
        "- Image Restoration\n",
        "- Autonomous Exploration\n",
        "- Localization"
      ],
      "metadata": {
        "id": "xC10BEislSZR"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Challenges CV systems\n",
        "\n",
        "\n",
        "| Factor                                | Challenges                                                                                                                                                                                |\n",
        "|---------------------------------------|-------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------------|\n",
        "| Variability in Data                  | The data collected from the real world is highly diverse, with variations in lighting, viewpoint, occlusions, and backgrounds, making it challenging for reliable computer vision systems to be developed. |\n",
        "| Scalability                           | Computer vision systems need to be scalable to manage large datasets and meet real-time processing requirements due to the continuous increase in visual data.                             |\n",
        "| Accuracy                              | Achieving high accuracy in object detection, scene interpretation, and tracking is a significant challenge, especially in complex or cluttered scenes, often due to noise, irrelevant features, and poor image quality. |\n",
        "| Robustness to Noise                  | Real-world data is noisy, containing defects, sensor artifacts, and distortions. Computer vision systems must be robust enough to handle and process such noisy data effectively.          |\n",
        "| Integration with Other Technologies   | Integrating computer vision with technologies like natural language processing, robotics, or augmented reality poses challenges related to system interoperability, expanding the usability of machine learning and computer vision. |\n",
        "| Privacy and Ethical Concerns          | Real-world applications of computer vision, especially in surveillance, facial recognition, and data gathering, raise concerns about privacy and ethics, necessitating proper handling of databases and personal information. |\n",
        "| Real-time Processing                  | Applications like autonomous vehicles and augmented reality require real-time processing, posing challenges in achieving the necessary computational efficiency, often requiring substantial computational power and capable cloud platforms. |\n",
        "| Long-term Reliability                 | Maintaining the reliability of computer vision systems over extended periods in real-life scenarios is challenging, as ensuring continued accuracy and flexibility can be difficult.         |\n",
        "| Generalization                        | Developing models with good generalization across diverse contexts and domains is a significant challenge, requiring the ability to adapt to changing circumstances without extensive retraining. |\n",
        "| Calibration and Maintenance           | Calibrating and maintaining hardware, such as cameras and sensors, in real-world settings presents challenges, often due to logistical complications and the need to withstand extreme weather conditions. |"
      ],
      "metadata": {
        "id": "Q34NTHdXmg0A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## ethical considerations\n",
        "\n",
        "![](https://huggingface.co/datasets/hf-vision/course-assets/resolve/743a2a115b53f258c9e6bc7744534d9e03b8a124/ethical_considerations.png)"
      ],
      "metadata": {
        "id": "yyjWRMaXmx8W"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7QI_bLNrcmed"
      },
      "outputs": [],
      "source": []
    }
  ]
}